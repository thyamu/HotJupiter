{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Accuracy vs. Temp (and spread) for the perturbed data by individual gas abundances (CO, CH4, NH3, H2O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def XGB_accuracy(X, Y):\n",
    "    # Split for training and testing\n",
    "    x_train, x_test, y_train, y_test = ms.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    eval_set = [(x_train, y_train), (x_test, y_test)]\n",
    "\n",
    "    # Fit the decision tree\n",
    "    classifier = xgb.XGBClassifier(objective=\"multi:softprob\", min_child_wight=10, max_depth=5, n_estimators=1000)\n",
    "    classifier = classifier.fit(x_train, y_train, early_stopping_rounds=100, eval_set=eval_set,\n",
    "                                eval_metric=[\"merror\", \"mlogloss\"], verbose=False)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    return metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "header = ['Metallicity', 'Altitude',\n",
    "        'Mean Degree',\n",
    "        'CO Degree', 'CH4 Degree', 'NH3 Degree', 'H2O Degree',\n",
    "        'Average shortest path length',\n",
    "        'Average clustering coefficient',\n",
    "        'CO clustering coefficient', 'CH4 clustering coefficient', 'NH3 clustering coefficient','H2O clustering coefficient',\n",
    "        'CO node betweenness centrality', 'CH4 node betweenness centrality', 'NH3 node betweenness centrality',\n",
    "        'H2O node betweenness centrality',\n",
    "        'Edge betweenness centrality',\n",
    "        'Average neighbor degree',\n",
    "        'CO neighbor degree', 'CH4 neighbor degree', 'NH3 neighbor degree', 'H2O neighbor degree',\n",
    "        'CO abundance', 'CH4 abundance', 'NH3 abundance', 'H2O abundance',\n",
    "        'Delta G distribution', 'Phi distribution',\n",
    "        'Average node betweenness centrality', 'Temperature', 'Kzz']\n",
    "\n",
    "header_average = [\n",
    "    'Mean Degree', 'Average shortest path length', 'Average clustering coefficient',\n",
    "    'Average neighbor degree','Average node betweenness centrality', 'Edge betweenness centrality']\n",
    "\n",
    "header_abundance = [n for n in header if n.find('abundance') > -1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### features for Delta G distribution + Abundance VS Kzz\n",
    "\n",
    "f1 = ['Delta G distribution'] + ['kzz']\n",
    "f2 = header_abundance + ['kzz']\n",
    "f3 = header_average + ['kzz']\n",
    "f4 = ['Delta G distribution'] + header_average + ['kzz']\n",
    "f5 = ['Delta G distribution'] + header_abundance + ['kzz']\n",
    "f6 = header_average + header_abundance + ['kzz']\n",
    "f7 = ['Delta G distribution'] + header_abundance + header_average + ['kzz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NH3 400 71.02150392532349\n",
      "NH3 500 117.06728172302246\n",
      "NH3 600 87.44561100006104\n",
      "NH3 700 209.64267301559448\n",
      "NH3 800 143.2902750968933\n",
      "NH3 900 127.08848786354065\n",
      "NH3 1000 239.13792514801025\n",
      "NH3 1100 206.0747950077057\n",
      "NH3 1200 421.25581073760986\n",
      "NH3 1300 184.75969099998474\n",
      "NH3 1400 153.74903988838196\n",
      "NH3 1500 112.12838983535767\n",
      "NH3 1600 121.28483700752258\n",
      "NH3 1700 166.38211679458618\n",
      "NH3 1800 211.32112789154053\n",
      "NH3 1900 263.65814113616943\n",
      "NH3 2000 251.83801293373108\n",
      "251.84034872055054\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "data_dir = \"/Users/hkim78/work/2020-hotJupiter/data/perturbed-data/2021/\"\n",
    "result_dir = \"/Users/hkim78/work/2020-hotJupiter/ML/results/perturbed_data/2021/\"\n",
    "\n",
    "dict_accuracy = dict()\n",
    "for removed_species in [\"CH4\", \"CO\", \"H2O\", \"NH3\"]:\n",
    "    dict_accuracy[removed_species] = dict()\n",
    "    for features in [\"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\"]:\n",
    "        dict_accuracy[removed_species][features] = list()\n",
    "\n",
    "for removed_species in [\"NH3\"]:\n",
    "    for t in np.arange(400, 2100, 100):\n",
    "        data0 = pd.read_csv(data_dir + '%s_removed/0.00 kzz analytical 50k spread observables '\n",
    "                                       '%s_removed %dK.csv'%(removed_species, removed_species, t))\n",
    "        data1 = pd.read_csv(data_dir + '%s_removed/1e06 kzz analytical 50k spread observables '\n",
    "                                       '%s_removed %dK.csv'%(removed_species, removed_species, t))\n",
    "        data2 = pd.read_csv(data_dir + '%s_removed/1e08 kzz analytical 50k spread observables '\n",
    "                                       '%s_removed %dK.csv'%(removed_species, removed_species, t))\n",
    "        data3 = pd.read_csv(data_dir + '%s_removed/1e10 kzz analytical 50k spread observables '\n",
    "                                       '%s_removed %dK.csv'%(removed_species, removed_species, t))\n",
    "\n",
    "        data0[\"kzz\"] = 0\n",
    "        data1[\"kzz\"] = 1\n",
    "        data2[\"kzz\"] = 2\n",
    "        data3[\"kzz\"] = 3\n",
    "\n",
    "        frames = [data0, data1, data2, data3]\n",
    "\n",
    "        allData = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "        allData1 = allData[f1]\n",
    "        allData2 = allData[f2]\n",
    "        allData3 = allData[f3]\n",
    "        allData4 = allData[f4]\n",
    "        allData5 = allData[f5]\n",
    "        allData6 = allData[f6]\n",
    "        allData7 = allData[f7]\n",
    "\n",
    "        # Split into dependent and independent variables\n",
    "        X1 = allData1.iloc[:, :-1]\n",
    "        Y1 = allData1.iloc[:, -1].values\n",
    "        a = XGB_accuracy(X1, Y1)\n",
    "        dict_accuracy[removed_species]['f1'].append(a)\n",
    "\n",
    "        X2 = allData2.iloc[:, :-1]\n",
    "        Y2 = allData2.iloc[:, -1].values\n",
    "        a = XGB_accuracy(X2, Y2)\n",
    "        dict_accuracy[removed_species]['f2'].append(a)    \n",
    "\n",
    "        X3 = allData3.iloc[:, :-1]\n",
    "        Y3 = allData3.iloc[:, -1].values\n",
    "        a = XGB_accuracy(X3, Y3)\n",
    "        dict_accuracy[removed_species]['f3'].append(a) \n",
    "\n",
    "        X4 = allData4.iloc[:, :-1]\n",
    "        Y4 = allData4.iloc[:, -1].values\n",
    "        a = XGB_accuracy(X4, Y4)\n",
    "        dict_accuracy[removed_species]['f4'].append(a) \n",
    "\n",
    "        X5 = allData5.iloc[:, :-1]\n",
    "        Y5 = allData5.iloc[:, -1].values\n",
    "        a = XGB_accuracy(X5, Y5)\n",
    "        dict_accuracy[removed_species]['f5'].append(a) \n",
    "\n",
    "        X6 = allData6.iloc[:, :-1]\n",
    "        Y6 = allData6.iloc[:, -1].values\n",
    "        a = XGB_accuracy(X6, Y6)\n",
    "        dict_accuracy[removed_species]['f6'].append(a) \n",
    "\n",
    "        X7 = allData5.iloc[:, :-1]\n",
    "        Y7 = allData5.iloc[:, -1].values\n",
    "        a = XGB_accuracy(X7, Y7)\n",
    "        dict_accuracy[removed_species]['f7'].append(a) \n",
    "\n",
    "    output_path = result_dir + \"accuracy_with_perturbation_%s.json\"%removed_species\n",
    "    with open(output_path, 'w') as outfile:\n",
    "        json.dump(dict_accuracy[removed_species], outfile)\n",
    "\n",
    "et = time.time()\n",
    "\n",
    "print(et - st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
